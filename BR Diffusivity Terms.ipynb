{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from remapping import mom_remapping\n",
    "import gsw\n",
    "from scipy.linalg import solve_banded\n",
    "from scipy.interpolate import interp1d\n",
    "import m6toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_url = 'https://data.nodc.noaa.gov/thredds/dodsC/woa/WOA13/DATAv2/temperature/netcdf/decav/1.00/woa13_decav_t00_01v2.nc'\n",
    "salt_url = 'https://data.nodc.noaa.gov/thredds/dodsC/woa/WOA13/DATAv2/salinity/netcdf/decav/1.00/woa13_decav_s00_01v2.nc'\n",
    "\n",
    "temp_url_025 = 'https://data.nodc.noaa.gov/thredds/dodsC/woa/WOA13/DATAv2/temperature/netcdf/A5B2/0.25/woa13_A5B2_t00_04v2.nc'\n",
    "salt_url_025 = 'https://data.nodc.noaa.gov/thredds/dodsC/woa/WOA13/DATAv2/salinity/netcdf/A5B2/0.25/woa13_A5B2_s00_04v2.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = Dataset(temp_url, 'r')\n",
    "salt = Dataset(salt_url, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat = temp.variables['lat'][:]\n",
    "lon = temp.variables['lon'][:]\n",
    "dep = temp.variables['depth'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lon_w = -25.5\n",
    "\n",
    "t_sect = temp.variables['t_an'][0,:,:,lon==lon_w].squeeze()\n",
    "s_sect = salt.variables['s_an'][0,:,:,lon==lon_w].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# empty columns are entirely masked\n",
    "empty = np.sum(~t_sect.mask, axis=0) == 0\n",
    "empty[169:] = True # mask above Greenland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lat = lat[~empty]\n",
    "t_sect = t_sect[:,~empty]\n",
    "s_sect = s_sect[:,~empty]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sa_sect = np.empty_like(s_sect)\n",
    "ct_sect = np.empty_like(t_sect)\n",
    "rho_sect = np.empty_like(s_sect)\n",
    "rhop_sect = np.empty_like(rho_sect)\n",
    "\n",
    "for i in range(s_sect.shape[1]):\n",
    "    sa_sect[:,i] = gsw.SA_from_SP(s_sect[:,i], dep, lon_w, lat[i])\n",
    "    ct_sect[:,i] = gsw.CT_from_t(sa_sect[:,i], t_sect[:,i], dep)\n",
    "    rho_sect[:,i] = gsw.rho(sa_sect[:,i], ct_sect[:,i], dep)\n",
    "    rhop_sect[:,i] = gsw.rho(sa_sect[:,i], ct_sect[:,i], 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sa_int = sa_sect\n",
    "ct_int = ct_sect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sa_lay = (sa_int[1:,:] + sa_int[:-1,:]) / 2\n",
    "ct_lay = (ct_int[1:,:] + ct_int[:-1,:]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# depths of all interfaces on which observations are present\n",
    "gr_int = np.ma.array(np.tile(dep.reshape(-1, 1), (1, sa_int.shape[1])), mask=sa_int.mask)\n",
    "\n",
    "# thicknesses of all layers between interfaces\n",
    "gr_th  = np.diff(gr_int, axis=0)\n",
    "\n",
    "# bottom interface at each column\n",
    "topo = gr_int.max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remap_cs = mom_remapping.Remapping_Cs()\n",
    "remap_cs.remapping_scheme = 4 # PQM_IH4IH3\n",
    "remap_cs.degree = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remap(h):\n",
    "    \"\"\"\n",
    "    Remap from original climatological grid according to h\n",
    "    \"\"\"\n",
    "\n",
    "    sa_remap = np.empty_like(h)\n",
    "    ct_remap = np.empty_like(h)\n",
    "\n",
    "    # remap by columns\n",
    "    for i in range(h.shape[1]):\n",
    "        # we need to make sure we deal with unmasking here,\n",
    "        # otherwise we'll get the fill values for thickness\n",
    "        # and salt/temp, which would be just a little weird\n",
    "        sa_remap[:,i] = mom_remapping.remapping_core_h(gr_th[:,i].compressed(),\n",
    "                                                       sa_lay[:,i].compressed(),\n",
    "                                                       h[:,i], remap_cs)\n",
    "        ct_remap[:,i] = mom_remapping.remapping_core_h(gr_th[:,i].compressed(),\n",
    "                                                       ct_lay[:,i].compressed(),\n",
    "                                                       h[:,i], remap_cs)\n",
    "        \n",
    "    return sa_remap, ct_remap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tdma(A, b):\n",
    "    x = b.copy()\n",
    "    \n",
    "    # modify first-row coefficients\n",
    "    A[0,1,:] /= A[1,0,:]\n",
    "    x[0,:]   /= A[1,0,:]\n",
    "    \n",
    "    # loop down (forward elimination)\n",
    "    for k in range(1, b.shape[0] - 1):\n",
    "        m = A[1,k,:] - A[2,k-1,:] * A[0,k,:]\n",
    "        A[0,k+1,:] /= m\n",
    "        x[k,:] = (x[k,:] - A[2,k-1,:] * x[k-1,:]) / m\n",
    "        \n",
    "    # final element\n",
    "    x[-1,:] = (x[-1,:] - A[2,-2,:] * x[-2,:]) / (A[1,-1,:] - A[2,-2,:] * A[0,-1,:])\n",
    "    \n",
    "    for k in range(b.shape[0] - 2, -1, -1):\n",
    "        x[k,:] -= A[0,k+1,:] * x[k+1,:]\n",
    "        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def diffuse(z_int, sa, ct, dt, c_surf, c_n2,\n",
    "            t_grid=3600, d_rho=0.5, d_surf=0):\n",
    "    \"\"\"\n",
    "    Use an implicit diffusivity equation to evolve the grid defined by z_int at timestep dt.\n",
    "    \"\"\"\n",
    "    \n",
    "    # calculate mid-layer positions\n",
    "    z_lay = (z_int[1:,:] + z_int[:-1,:]) / 2\n",
    "    \n",
    "    # gravity used by gsw\n",
    "    g = 9.7963\n",
    "    \n",
    "    I = z_int.shape[0] - 1 # number of layers\n",
    "    A = np.zeros((3, I+1, z_int.shape[1])) # diffusion system coefficients\n",
    "\n",
    "    # iterate over columns\n",
    "    for i in range(z_int.shape[1]):\n",
    "        if c_n2 > 0:\n",
    "            # calculate local buoyancy term at interfaces\n",
    "            # from temp/salt data at the centre of layers\n",
    "            n2, z_c = gsw.Nsquared(sa[:,i], ct[:,i], z_lay[:,i])\n",
    "            # drho_dz term to convert to distance\n",
    "            dz_r = np.maximum((n2 * 1e4) / g**2, 1e-20)\n",
    "            # diffusivity coefficient on interfaces\n",
    "            k_n2_int = dz_r / d_rho\n",
    "            # interpolate the diffusivity coefficient from interfaces\n",
    "            # to layers, where they apply in the diffusion equation\n",
    "            # we have to (linearly) extrapolate into the top and\n",
    "            # bottom layers, because we don't have the buoyancy frequency at\n",
    "            # the surface or the very bottom\n",
    "            f = interp1d(z_c, k_n2_int, bounds_error=False, fill_value=\"extrapolate\")\n",
    "            k_n2 = np.maximum(f(z_lay[:,i]), 0)\n",
    "        else:\n",
    "            k_n2 = np.zeros_like(z_lay[:,i])\n",
    "        \n",
    "        # determine total grid coefficient from\n",
    "        # background term 1/D, where D is local depth\n",
    "        # surface stretching 1/(d + d_0) for distance\n",
    "        # from surface d, and factor d_0\n",
    "        #\n",
    "        # k_grid = D/tgrid * (c_surf*k_surf + c_n2*k_n2 + c_b*k_b)\n",
    "        k_grid = (z_int[-1,i] * (c_surf / (d_surf + z_lay[:,i]) + \\\n",
    "                                 c_n2 * k_n2) \\\n",
    "                  + (1 - c_n2 - c_surf)) / t_grid\n",
    "\n",
    "        # fill in implicit system coefficients\n",
    "        A[0,2:,i]     = -dt * I**2 * k_grid[1:]\n",
    "        A[2,:-2,i]    = -dt * I**2 * k_grid[:-1]\n",
    "        A[1,[0,-1],i] = 1 # boundary conditions\n",
    "        A[1,1:-1,i]   = 1 + I**2 * dt * (k_grid[1:] + k_grid[:-1])\n",
    "\n",
    "        # solve tridiagonal system\n",
    "        #z_next[:,i] = solve_banded((1, 1), A, z_int[:,i],\n",
    "        #                           overwrite_ab=True, check_finite=False)\n",
    "        \n",
    "    # solve tridiagonal system for everywhere at once\n",
    "    z_new = tdma(A, z_int)\n",
    "    \n",
    "    h = np.diff(z_new, axis=0)\n",
    "    h = np.maximum(h, 1e-10)\n",
    "    h *= z_int[-1,:] / np.sum(h, axis=0)\n",
    "    \n",
    "    return np.concatenate((np.zeros((1, h.shape[1])), h.cumsum(axis=0)), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Diffusivity Terms - Grids\n",
    "### Uniform\n",
    "\n",
    "First we define a uniform grid, where layers vanish when they intersect topography."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 75\n",
    "# uniform thickness from 0 to max topo with n layers\n",
    "h = np.ones((n,lat.size)) * topo.max() / n\n",
    "\n",
    "h_i = np.where(h.cumsum(axis=0) > topo)\n",
    "# deflate all layers below topography\n",
    "h[h_i] = 1e-3\n",
    "# get unique latitudes (to get the first cell that needs inflation)\n",
    "_, i = np.unique(h_i[1], return_index=True)\n",
    "# inflate\n",
    "h[h_i[0][i], h_i[1][i]] += (topo - h.sum(axis=0))[h_i[1][i]]\n",
    "\n",
    "sa, ct = remap(h)\n",
    "\n",
    "z = np.concatenate((np.zeros((1, h.shape[1])), h.cumsum(axis=0)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.pcolormesh(lat, z, h)\n",
    "plt.plot(lat, z.T, 'k', linewidth=0.4)\n",
    "plt.colorbar()\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OM4\n",
    "\n",
    "We also use the OM4 grid with the `dz_f1` helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dz_f1(n, dz_min, total, power, precision):\n",
    "    dz = np.empty(n)\n",
    "    \n",
    "    # initial profile\n",
    "    for i in range(n):\n",
    "        dz[i] = (i / (n - 1)) ** power\n",
    "    \n",
    "    # rescale to total depth and round to precision\n",
    "    dz[:] = (total - n*dz_min) * (dz[:] / np.sum(dz))\n",
    "    dz[:] = np.around(dz[:], decimals=precision)\n",
    "    \n",
    "    # adjust bottom\n",
    "    dz[-1] += total - np.sum(dz[:] + dz_min)\n",
    "    dz[-1] = np.around(dz[-1], decimals=precision)\n",
    "    \n",
    "    dz[:] += dz_min\n",
    "    \n",
    "    return dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dz_75 = dz_f1(75, 2, 4000, 4.5, 2)\n",
    "z_75 = np.insert(dz_75.cumsum(), 0, 0)[:,np.newaxis]\n",
    "z_75_full = np.tile(z_75, (1, sa_sect.shape[1]))\n",
    "\n",
    "# clip at topography\n",
    "np.putmask(z_75_full, z_75_full > topo, topo)\n",
    "# slightly inflate vanished layers (we should adjust the full layer thickness here...)\n",
    "h_75 = np.maximum(np.diff(z_75_full, axis=0), 1e-10)\n",
    "# recalculate interfaces\n",
    "z_75 = np.concatenate((np.zeros((1, h_75.shape[1])), h_75.cumsum(axis=0)), axis=0)\n",
    "sa_75, ct_75 = remap(h_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.pcolormesh(lat, z_75, h_75)\n",
    "plt.plot(lat, z_75.T, 'k', linewidth=0.4)\n",
    "plt.colorbar()\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Burchard and Rennau Terms\n",
    "We can investigate the individual Burchard and Rennau diffusivity terms.\n",
    "\n",
    "## Buoyancy Frequency\n",
    "### Uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z_n2 = z.copy()\n",
    "sa_n2 = sa\n",
    "ct_n2 = ct\n",
    "\n",
    "for i in range(10):\n",
    "    z_n2 = diffuse(z_n2, sa_n2, ct_n2,\n",
    "                   dt=100, t_grid=3*3600,\n",
    "                   c_n2=1.0, c_surf=0.0)\n",
    "    h_n2 = np.diff(z_n2, axis=0)\n",
    "    sa_n2, ct_n2 = remap(h_n2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.pcolormesh(lat, z_n2, h_n2)\n",
    "plt.plot(lat, z_n2.T, 'w', linewidth=0.5)\n",
    "plt.colorbar()\n",
    "plt.title('purely buoyancy diffusivity (uniform IC)')\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OM4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z_n2_75 = z_75.copy()\n",
    "sa_n2_75 = sa_75\n",
    "ct_n2_75 = ct_75\n",
    "\n",
    "for i in range(10):\n",
    "    z_n2_75 = diffuse(z_n2_75, sa_n2_75, ct_n2_75,\n",
    "                      dt=100, t_grid=3*3600,\n",
    "                      c_n2=1.0, c_surf=0.0)\n",
    "    h_n2_75 = np.diff(z_n2_75, axis=0)\n",
    "    sa_n2_75, ct_n2_75 = remap(h_n2_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.pcolormesh(lat, z_n2_75, h_n2_75)\n",
    "plt.plot(lat, z_n2_75.T, 'w', linewidth=0.5)\n",
    "plt.colorbar()\n",
    "plt.title('purely buoyancy diffusivity (OM4 IC)')\n",
    "plt.gca().invert_yaxis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
