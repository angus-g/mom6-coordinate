{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Generation on Climatology\n",
    "\n",
    "As a first step in coordinate development, we'll work on sections of climatology from [WOA13](https://www.nodc.noaa.gov/OC5/woa13/). Because temperature is given in-situ, we first have to convert to potential temperature. Similar to [convert_WOA13](https://github.com/adcroft/convert_WOA13), we use the Python `gsw` package, which implements TEOS-10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from remapping import mom_remapping\n",
    "import gsw\n",
    "from scipy.linalg import solve_banded\n",
    "from scipy.interpolate import interp1d\n",
    "import m6toolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an initial set of input files, we load up THREDDS URLs for monthly averaged climatologies from 2005-2012."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_format = 'https://data.nodc.noaa.gov/thredds/dodsC/woa/WOA13/DATAv2/{}/netcdf/A5B2/1.00/woa13_A5B2_{}{:02}_01v2.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_format_025 = 'https://data.nodc.noaa.gov/thredds/dodsC/woa/WOA13/DATAv2/{}/netcdf/A5B2/0.25/woa13_A5B2_{}{:02}_04v2.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_urls = [url_format.format('temperature', 't', i+1) for i in range(12)]\n",
    "salt_urls = [url_format.format('salinity', 's', i+1) for i in range(12)]\n",
    "\n",
    "temp_urls_025 = [url_format_025.format('temperature', 't', i+1) for i in range(12)]\n",
    "salt_urls_025 = [url_format_025.format('salinity', 's', i+1) for i in range(12)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sections\n",
    "\n",
    "Although our choice of coordinate should apply globally, we're particularly interested in a few troublesome spots, where there tend to always be problems, such as the Denmark Strait and the Sulu Sea. We may also care about dense overflows off Antarctica.\n",
    "\n",
    "## Atlantic\n",
    "We have an Atlantic section at around 25 degrees west, which should include a portion of Denmark Strait overflow. We'll start with state data from the 1 degree WOA13 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp = Dataset(temp_urls[0], 'r')\n",
    "salt = Dataset(salt_urls[0], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat = temp.variables['lat'][:]\n",
    "lon = temp.variables['lon'][:]\n",
    "dep = temp.variables['depth'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lon_w = -25.5\n",
    "#lon_i = (lon_s <= lon) & (lon <= lon_e)\n",
    "\n",
    "t_sect = temp.variables['t_an'][0,:,:,lon==lon_w].squeeze()\n",
    "s_sect = salt.variables['s_an'][0,:,:,lon==lon_w].squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to take an contiguous latitude section, so we'll remove Greenland and everything north of it, as well as Antarctica. There's also a weird masked column at around 35 which is probably an island..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# empty columns are entirely masked\n",
    "empty = np.sum(~t_sect.mask, axis=0) == 0\n",
    "empty[169:] = True # mask above Greenland"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lat = lat[~empty]\n",
    "t_sect = t_sect[:,~empty]\n",
    "s_sect = s_sect[:,~empty]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using TEOS-10, we can convert from practical salinity to absolute salinity, and from in-situ temperature to conservative temperature. From here, we can compute the locally-referenced density, and the potential density referenced to 2000m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sa_sect = np.empty_like(s_sect)\n",
    "ct_sect = np.empty_like(t_sect)\n",
    "rho_sect = np.empty_like(s_sect)\n",
    "rhop_sect = np.empty_like(rho_sect)\n",
    "\n",
    "for i in range(s_sect.shape[1]):\n",
    "    sa_sect[:,i] = gsw.SA_from_SP(s_sect[:,i], dep, lon_w, lat[i])\n",
    "    ct_sect[:,i] = gsw.CT_from_t(sa_sect[:,i], t_sect[:,i], dep)\n",
    "    rho_sect[:,i] = gsw.rho(sa_sect[:,i], ct_sect[:,i], dep)\n",
    "    rhop_sect[:,i] = gsw.rho(sa_sect[:,i], ct_sect[:,i], 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the two density sections, the locally-refenced density and the potential density referenced to 2000m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = plt.subplot(211)\n",
    "plt.pcolormesh(lat, dep, rho_sect)\n",
    "ax.invert_yaxis()\n",
    "#plt.colorbar()\n",
    "\n",
    "ax = plt.subplot(212)\n",
    "plt.pcolormesh(lat, dep, rhop_sect)\n",
    "ax.invert_yaxis()\n",
    "#plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation Grid\n",
    "\n",
    "We have observations at particular depth levels, which are given by masking the depth coordinate by the mask from a particular column of our temp/salt data. We assume these observations are at interfaces (because we have an observation at z=0, for example), and therefore we calculate layer averages from these so that we can perform remapping later. We also store the actual depth of each column (we don't have partial-cell topography available though) so that we can ensure regularity of our interpolated grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# depths of all interfaces on which observations are present\n",
    "gr_int = np.ma.array(np.tile(dep.reshape(-1, 1), (1, t_sect.shape[1])), mask=t_sect.mask)\n",
    "\n",
    "# thicknesses of all layers between interfaces\n",
    "gr_th  = np.diff(gr_int, axis=0)\n",
    "\n",
    "# bottom interface at each column\n",
    "topo = gr_int.max(axis=0).compressed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sa_lay = sa_sect[:-1,:] + np.diff(sa_sect, axis=0) / gr_th\n",
    "ct_lay = ct_sect[:-1,:] + np.diff(ct_sect, axis=0) / gr_th"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remapping\n",
    "\n",
    "Now we can define a function that will remap from our source data to any target grid.\n",
    "\n",
    "**Note:** *We might want to do this for temp/salt rather than conservative temp and absolute salt?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "remap_cs = mom_remapping.Remapping_Cs()\n",
    "remap_cs.remapping_scheme = 4 # PQM_IH4IH3\n",
    "remap_cs.degree = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remap(h):\n",
    "    \"\"\"\n",
    "    Remap from original climatological grid according to h\n",
    "    \"\"\"\n",
    "\n",
    "    sa_remap = np.empty_like(h)\n",
    "    ct_remap = np.empty_like(h)\n",
    "\n",
    "    # remap by columns\n",
    "    for i in range(h.shape[1]):\n",
    "        # we need to make sure we deal with unmasking here,\n",
    "        # otherwise we'll get the fill values for thickness\n",
    "        # and salt/temp, which would be just a little weird\n",
    "        sa_remap[:,i] = mom_remapping.remapping_core_h(gr_th[:,i].compressed(),\n",
    "                                                       sa_lay[:,i].compressed(),\n",
    "                                                       h[:,i], remap_cs)\n",
    "        ct_remap[:,i] = mom_remapping.remapping_core_h(gr_th[:,i].compressed(),\n",
    "                                                       ct_lay[:,i].compressed(),\n",
    "                                                       h[:,i], remap_cs)\n",
    "        \n",
    "    return sa_remap, ct_remap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Generation\n",
    "\n",
    "We can go about generating the grid using the Hofmeister et al. (2010) technique. This involves a vertical grid diffusion to optimise for buoyancy, shear, near-surface zooming and a background component. Then we're left with an isopycnal or neutral density curvature tendency term.\n",
    "\n",
    "## Neutral Density Curvature\n",
    "\n",
    "First, we'll define a function to calculate the neutral density curvature `ndc` at interfaces, which is where we need to calculate the tendency term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ndc_int(z_int, sa_lay, ct_lay):\n",
    "    \"\"\"\n",
    "    Calculate neutral density curvature between\n",
    "    adjacent columns, given their (absolute) salinity, (conservative)\n",
    "    temperature and physical positions (or pressure).\n",
    "    \n",
    "    z_int gives the current location of all model interfaces,\n",
    "    and sa_lay and ct_lay give the absolute salinity and conservative\n",
    "    temperature cell mean values between these interfaces.\n",
    "    \"\"\"\n",
    "    \n",
    "    def d(x):\n",
    "        \"\"\"\n",
    "        Calculate diff and squeeze\n",
    "        \"\"\"\n",
    "        \n",
    "        return np.diff(x, axis=1).squeeze()\n",
    "    \n",
    "    # first, calculate layer thicknesses\n",
    "    h = np.diff(z_int, axis=0)\n",
    "    \n",
    "    # use the layer thicknesses to interpolate interface values\n",
    "    # using weighted average of the cell mean values on either side\n",
    "    sa_int = (sa_lay[1:,:] * h[1:,:] + sa_lay[:-1,:] * h[:-1,:]) / (h[1:,:] + h[:-1,:])\n",
    "    ct_int = (ct_lay[1:,:] * h[1:,:] + ct_lay[:-1,:] * h[:-1,:]) / (h[1:,:] + h[:-1,:])\n",
    "    \n",
    "    # drop top and bottom interfaces, since we won't calculate\n",
    "    # the curvature at either of these places (those interfaces\n",
    "    # can't move)\n",
    "    z_int = z_int[1:-1]\n",
    "    \n",
    "    # for dealing with edges, extend data with a ghost column\n",
    "    # to give a Neumann boundary condition (dC/dx = 0)\n",
    "    int_gst = np.concatenate([ z_int[:,[0]],  z_int,  z_int[:,[-1]]], axis=1)\n",
    "    sa_gst  = np.concatenate([sa_int[:,[0]], sa_int, sa_int[:,[-1]]], axis=1)\n",
    "    ct_gst  = np.concatenate([ct_int[:,[0]], ct_int, ct_int[:,[-1]]], axis=1)\n",
    "    \n",
    "    # neutral density curvature *on interfaces*\n",
    "    ndc = np.empty_like(z_int)\n",
    "\n",
    "    # calculate for each (real) column\n",
    "    for i in range(ndc.shape[1]):\n",
    "        # calculate difference to column at left\n",
    "        # first, we need the mean S, T and P between\n",
    "        # the centre and left\n",
    "        sa =  sa_gst[:,[i,i+1]]\n",
    "        ct =  ct_gst[:,[i,i+1]]\n",
    "        z  = int_gst[:,[i,i+1]]\n",
    "\n",
    "        # now calculate the density, thermal expansion and\n",
    "        # haline contraction at these mean values\n",
    "        r, a, b = gsw.rho_alpha_beta(sa.mean(axis=1),\n",
    "                                     ct.mean(axis=1),\n",
    "                                      z.mean(axis=1))\n",
    "        # use these to calculate the actual neutral density difference\n",
    "        ndd_l = r * (b * d(sa) - a * d(ct))\n",
    "        \n",
    "        # use the same process as above\n",
    "        # to calculate difference to column at right        \n",
    "        sa =  sa_gst[:,[i+2,i+1]]\n",
    "        ct =  ct_gst[:,[i+2,i+1]]\n",
    "        z  = int_gst[:,[i+2,i+1]]\n",
    "\n",
    "        r, a, b = gsw.rho_alpha_beta(sa.mean(axis=1),\n",
    "                                     ct.mean(axis=1),\n",
    "                                      z.mean(axis=1))\n",
    "        ndd_r = r * (b * d(sa) - a * d(ct))\n",
    "\n",
    "        ndc[:,i] = ndd_r + ndd_l\n",
    "        \n",
    "    return ndc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "Let's take a look at these neutral density differences `ndc`, on the uniform grid 50 level grid remapped from the source data. First we show the original potential density field from the remapped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 50\n",
    "# uniform thickness from 0 to topo with n layers\n",
    "h = np.linspace(0, 1, n).reshape(-1,1) * 2 * topo / n\n",
    "s, t = remap(h)\n",
    "\n",
    "plt.pcolormesh(gsw.rho(s, t, 2000))\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we actually calculate the curvature and print some statistics to see what kind of numbers we're dealing with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = np.concatenate((np.zeros((1, h.shape[1])), h.cumsum(axis=0)), axis=0)\n",
    "ndc = ndc_int(z, s, t)\n",
    "\n",
    "print('min:\\t\\t{}\\nmax:\\t\\t{}\\nmean:\\t\\t{}\\nmean (abs):\\t{}\\nsd:\\t\\t{}\\nsd (abs):\\t{}'.format(\n",
    "    ndc.min(), ndc.max(), ndc.mean(), np.abs(ndc).mean(), ndc.std(), np.abs(ndc).std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.pcolormesh(lat, z[1:-1], np.log10(np.abs(ndc)))\n",
    "plt.gca().invert_yaxis()\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diffusing interfaces\n",
    "\n",
    "Now we define a function to compute the optimised interface positions according to the diffusivitye quation. For the moment, we've only included the surface zooming, buoyancy and background terms. This is because we don't have any velocity data from which to calculate the shear term. We could however calculate the shear term from thermal wind if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def diffuse(z_int, c_surf, d_surf, c_n2, dt, t_grid=3600, d_rho=0.5):\n",
    "    \"\"\"\n",
    "    Use an implicit diffusivity equation to evolve the grid defined by z_int at timestep dt.\n",
    "    \"\"\"\n",
    "    \n",
    "    # allocate new grid\n",
    "    z_next = np.empty_like(z_int)\n",
    "    z_lay = (z_int[1:,:] + z_int[:-1,:]) / 2\n",
    "    \n",
    "    # gravity used by gsw\n",
    "    g = 9.7963\n",
    "    \n",
    "    I = z_int.shape[0] - 1 # number of layers\n",
    "    A = np.zeros((3, I+1)) # diffusion system coefficients\n",
    "\n",
    "    # iterate over columns\n",
    "    for i in range(z_int.shape[1]):\n",
    "        # calculate local buoyancy term at interfaces\n",
    "        # from temp/salt data at the centre of layers\n",
    "        n2, z_c = gsw.Nsquared(sa[:,i], ct[:,i], z_lay[:,i])\n",
    "        # drho_dz term to convert to distance\n",
    "        dz_r = np.maximum((n2 * 1e4) / g**2, 0)\n",
    "        # diffusivity coefficient on interfaces\n",
    "        k_n2_int = dz_r / d_rho\n",
    "        # interpolate the diffusivity coefficient from interfaces\n",
    "        # to layers, where they apply in the diffusion equation\n",
    "        # we have to (linearly) extrapolate into the top and\n",
    "        # bottom layers, because we don't have the buoyancy frequency at\n",
    "        # the surface or the very bottom\n",
    "        f = interp1d(z_c, k_n2_int, bounds_error=False, fill_value=\"extrapolate\")\n",
    "        k_n2 = f(z_lay[:,i])\n",
    "        \n",
    "        # determine total grid coefficient from\n",
    "        # background term 1/D, where D is local depth\n",
    "        # surface stretching 1/(d + d_0) for distance\n",
    "        # from surface d, and factor d_0\n",
    "        #\n",
    "        # k_grid = D/tgrid * (c_surf*k_surf + c_n2*k_n2 + c_b*k_b)\n",
    "        k_grid = (z_int[-1,i] * (c_surf / (d_surf + np.maximum(z_lay[:,i], 0)) + \\\n",
    "                                 c_n2 * k_n2) \\\n",
    "                  + (1 - c_n2 - c_surf)) / t_grid\n",
    "\n",
    "        # fill in implicit system coefficients\n",
    "        A[0,2:]     = -dt * I**2 * k_grid[1:]\n",
    "        A[2,:-2]    = -dt * I**2 * k_grid[:-1]\n",
    "        A[1,[0,-1]] = 1 # boundary conditions\n",
    "        A[1,1:-1]   = 1 + I**2 * dt * (k_grid[1:] + k_grid[:-1])\n",
    "\n",
    "        # solve tridiagonal system\n",
    "        z_next[:,i] = solve_banded((1, 1), A, z_int[:,i])\n",
    "        \n",
    "    return z_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neutral Density Curvature Tendency\n",
    "\n",
    "Instead of including the adaptation to neutral density curvature into the diffusion equation, we can implement it in a separate step, where the neutral density curvature is converted to a tendency, depending on the local stratification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ndc_tendency(z_int, sa, ct):\n",
    "    \"\"\"\n",
    "    Calculate interfacial tendency according to\n",
    "    the neutral density curvature, calculated on\n",
    "    interfaces.\n",
    "    \"\"\"\n",
    "    \n",
    "    # gravity used by gsw\n",
    "    g = 9.7963\n",
    "    \n",
    "    # calculate neutral density curvature on the interfaces\n",
    "    ndc = ndc_int(z_int, sa, ct)\n",
    "    \n",
    "    # calculate local buoyancy frequency on interfaces to get convert from\n",
    "    # density differences to an interfacial displacement\n",
    "    n2 = gsw.Nsquared(sa, ct, (z_int[1:,:] + z_int[:-1,:]) / 2)[0]\n",
    "    # set a minimum value of n2 so we don't divide by zero\n",
    "    n2 = np.maximum(n2, 1e-10)\n",
    "    dz = (g**2 * ndc) / (1e4 * n2)\n",
    "\n",
    "    # maximum interface movement is limited by half layer thickness in\n",
    "    # the direction the interface is moving\n",
    "    h = np.diff(z_int, axis=0)\n",
    "    h_i = np.arange(dz.shape[0])[:,np.newaxis] + (np.sign(dz) / 2 + 0.5).astype(int)\n",
    "    h_j = np.tile(np.arange(h_i.shape[1])[np.newaxis,:], (h_i.shape[0], 1))\n",
    "    h_dz = h[h_i,h_j]\n",
    "    dz = np.sign(dz) * np.minimum(np.abs(dz), h_dz / 2)\n",
    "    \n",
    "    return dz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation Algorithm\n",
    "\n",
    "Now we have the generation algorithm as follows:\n",
    "\n",
    "- move interfaces according to their isopycnal/neutral density curvature tendency (3D term)\n",
    "- enforce grid regularity\n",
    "  - minimum thickess of all layers\n",
    "  - conservation of total column thickness\n",
    "- optimise interfaces according to diffusion equation, based on e.g. buoyancy or distance from surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate(z, sa, ct, dt, alpha=0.5, isopycnal=False):\n",
    "    \"\"\"\n",
    "    Return a new grid specified by interface positions\n",
    "    for a current grid given by interface positions\n",
    "    as well as the density variables and an optimisation\n",
    "    timestep.\n",
    "    \n",
    "    Parameter alpha determines the amount of tendency used\n",
    "    to move interfaces in the 3D step (based on neutral\n",
    "    density curvature or target isopycnals).\n",
    "    \"\"\"\n",
    "    \n",
    "    z_new = z.copy()\n",
    "    \n",
    "    if isopycnal:\n",
    "        # calculate grid tendency from target isopycnals\n",
    "        dz_tend = 0 # TODO: implement\n",
    "    else:\n",
    "        # calculate grid tendency term from neutral density curvature\n",
    "        dz_tend = ndc_tendency(z, sa, ct)\n",
    "    \n",
    "    # apply tendency to interior interfaces\n",
    "    z_new[1:-1] += alpha * dz_tend\n",
    "    \n",
    "    # calculate new layer thickness and\n",
    "    # enforce minimum layer thickness and positive depths\n",
    "    h = np.diff(z_new, axis=0)\n",
    "    # 1mm thick minimum\n",
    "    h = np.maximum(h, 1e-3)\n",
    "    \n",
    "    # reinflate each column\n",
    "    # weight layers through the water column, for example\n",
    "    # to give thinner surface layers\n",
    "    w = 1 # uniform weighting\n",
    "    h *= w\n",
    "    # use actual bottom depths\n",
    "    h *= topo / np.sum(h, axis=0)\n",
    "    \n",
    "    # check that we didn't introduce any negative thickness layers\n",
    "    if np.any(h < 0):\n",
    "        print('negative thickness at iteration', k)\n",
    "    \n",
    "    # recalculate z from h\n",
    "    z_new = np.concatenate((np.zeros((1, h.shape[1])), h.cumsum(axis=0)), axis=0)\n",
    "    \n",
    "    # check that the total column thickness is preserved\n",
    "    if np.any(np.abs(z_new[-1,:] - topo) > 1e-10):\n",
    "        print('bottom moved at iteration', k)\n",
    "        print(z_new[-1,:] - topo)\n",
    "    \n",
    "    # optimise layers by diffusion\n",
    "    return diffuse(z_new, c_surf=0.2, d_surf=100, c_n2=0.3, dt=100, t_grid=3600, d_rho=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing generation algorithm\n",
    "\n",
    "Let's test the generation algorithm in a few cases. The first is to use the neutral density curvature as a tendency term for adjusting the grid, and the second is to move the grid toward target isopycnals. In both cases, we start with a 50-layer sigma grid (i.e. uniform thickness layers, distributed between the surface and local topography)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define initial uniform grid with 50 layers\n",
    "n = 50\n",
    "# uniform thickness from 0 to topo with n layers\n",
    "h = np.linspace(0, 1, n).reshape(-1,1) * 2 * topo / n\n",
    "z = np.concatenate((np.zeros((1, h.shape[1])), h.cumsum(axis=0)), axis=0)\n",
    "sa, ct = remap(h)\n",
    "\n",
    "# save initial neutral density curvature and density to see\n",
    "# how things change after iteration (see above for plots of these\n",
    "# quantities)\n",
    "ndc_init  = ndc_int(z, sa, ct)\n",
    "rhop_init = gsw.rho(sa, ct, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neutral density curvature generation\n",
    "\n",
    "First we'll use the neutral density curvature, along with the regular grid diffusion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "z_ndc = z.copy()\n",
    "sa_ndc = sa\n",
    "ct_ndc = ct\n",
    "\n",
    "for i in range(10):\n",
    "    z_ndc = generate(z_ndc, sa_ndc, ct_ndc, dt=100)\n",
    "    h_ndc = np.diff(z_ndc, axis=0)\n",
    "    sa_ndc, ct_ndc = remap(h_ndc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.pcolormesh(h_ndc)\n",
    "plt.gca().invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ndc_final = ndc_int(z_ndc, sa_ndc, ct_ndc)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "ax = plt.subplot(211)\n",
    "plt.pcolormesh(ndc_final)\n",
    "plt.colorbar()\n",
    "ax.invert_yaxis()\n",
    "\n",
    "ax = plt.subplot(212)\n",
    "plt.pcolormesh(ndc_final - ndc_init)\n",
    "plt.colorbar()\n",
    "ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rhop_final = gsw.rho(sa_ndc, ct_ndc, 2000)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "ax = plt.subplot(211)\n",
    "plt.pcolormesh(rhop_final)\n",
    "plt.colorbar()\n",
    "ax.invert_yaxis()\n",
    "\n",
    "ax = plt.subplot(212)\n",
    "plt.pcolormesh(rhop_final - rhop_init)\n",
    "plt.colorbar()\n",
    "ax.invert_yaxis()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
